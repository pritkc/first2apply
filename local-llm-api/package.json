{
  "name": "local-llm-api",
  "version": "1.0.0",
  "description": "Local LLM API server compatible with OpenAI API format",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js"
  },
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5"
  },
  "devDependencies": {
    "nodemon": "^3.0.1"
  }
}
